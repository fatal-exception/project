{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "def head(stream, n=10):\n",
    "    return list(itertools.islice(stream,n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import smart_open, simple_preprocess\n",
    "from gensim.corpora.wikicorpus import _extract_pages, filter_wiki\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) \n",
    "            if token not in STOPWORDS]\n",
    "\n",
    "def iter_wiki(dump_file):\n",
    "    ignore_namespaces = 'Wikipedia Category File Portal\\\n",
    "    Template MediaWiki User Help Book Draft'.split()\n",
    "    \n",
    "    for title, text, pageid in _extract_pages(smart_open(dump_file)):\n",
    "        text = filter_wiki(text)\n",
    "        tokens = tokenize(text)\n",
    "        if len(tokens) < 50 or any(title.startswith(ns + \":\") for ns in ignore_namespaces):\n",
    "            continue\n",
    "        yield title,tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April [u'april', u'th', u'month', u'year', u'comes', u'march', u'months', u'days', u'april', u'begins']\n",
      "August [u'august', u'aug', u'th', u'month', u'year', u'gregorian', u'calendar', u'coming', u'july', u'september']\n",
      "Art [u'painting', u'renoir', u'work', u'art', u'art', u'creative', u'activity', u'people', u'people', u'called']\n",
      "A [u'page', u'letter', u'alphabet', u'indefinite', u'article', u'article', u'grammar', u'uses', u'disambiguation', u'thumb']\n",
      "Air [u'air', u'fan', u'air', u'air', u'earth', u'atmosphere', u'air', u'mixture', u'gases', u'dust']\n",
      "Autonomous communities of Spain [u'spain', u'divided', u'parts', u'called', u'autonomous', u'communities', u'autonomous', u'means', u'autonomous', u'communities']\n",
      "Alan Turing [u'statue', u'alan', u'turing', u'rebuild', u'machine', u'alan', u'turing', u'alan', u'mathison', u'turing']\n",
      "Alanis Morissette [u'alanis', u'nadine', u'morissette', u'born', u'june', u'grammy', u'award', u'winning', u'canadian', u'american']\n"
     ]
    }
   ],
   "source": [
    "stream = iter_wiki('./data/simplewiki-20180101-pages-articles.xml.bz2')\n",
    "for title, tokens in itertools.islice(iter_wiki('./data/simplewiki-20180101-pages-articles.xml.bz2'), 8):\n",
    "    print(title, tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_stream = (tokens for _, tokens in iter_wiki('./data/simplewiki-20180101-pages-articles.xml.bz2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO : adding document #10000 to Dictionary(157080 unique tokens: [u'fawn', u'\\u03c9\\u0431\\u0440\\u0430\\u0434\\u043e\\u0432\\u0430\\u043d\\u043d\\u0430\\u0467', u'vang', u'yollar\\u0131', u'idaira']...)\n",
      "INFO : adding document #20000 to Dictionary(233346 unique tokens: [u'biennials', u'sowela', u'tsukino', u'clottes', u'refreshable']...)\n",
      "INFO : adding document #30000 to Dictionary(293307 unique tokens: [u'biennials', u'sowela', u'tsukino', u'clottes', u'klatki']...)\n",
      "INFO : adding document #40000 to Dictionary(368196 unique tokens: [u'biennials', u'sowela', u'biysk', u'sermersheim', u'wooda']...)\n",
      "INFO : adding document #50000 to Dictionary(416860 unique tokens: [u'biennials', u'sowela', u'biysk', u'sermersheim', u'wooda']...)\n",
      "INFO : adding document #60000 to Dictionary(454791 unique tokens: [u'biennials', u'sowela', u'biysk', u'sermersheim', u'wooda']...)\n",
      "INFO : built Dictionary(481491 unique tokens: [u'biennials', u'sowela', u'biysk', u'sermersheim', u'wooda']...) from 62608 documents (total 13322526 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 59s, sys: 4.96 s, total: 7min 4s\n",
      "Wall time: 7min 7s\n",
      "Dictionary(481491 unique tokens: [u'biennials', u'sowela', u'biysk', u'sermersheim', u'wooda']...)\n"
     ]
    }
   ],
   "source": [
    "%time id2word_wiki = gensim.corpora.Dictionary(doc_stream)\n",
    "print(id2word_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
